\documentclass[journal,12pt,onecolumn]{IEEEtran}
\usepackage{cite}
\usepackage{graphicx}
\usepackage{amsmath,amssymb,amsfonts,amsthm}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{txfonts}
\usepackage{listings}
\usepackage{enumitem}
\usepackage{mathtools}
\usepackage{gensymb}
\usepackage{comment}
\usepackage[breaklinks=true]{hyperref}
\usepackage{tkz-euclide} 
\usepackage{listings}
\usepackage{gvv}                                        
%\def\inputGnumericTable{}                                 
\usepackage[latin1]{inputenc} 
\usetikzlibrary{arrows.meta, positioning}
\usepackage{xparse}
\usepackage{color}                                            
\usepackage{array}                                            
\usepackage{longtable}                                       
\usepackage{calc}                                             
\usepackage{multirow}
\usepackage{multicol}
\usepackage{hhline}                                           
\usepackage{ifthen}                                           
\usepackage{lscape}
\usepackage{tabularx}
\usepackage{array}
\usepackage{float}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{problem}{Problem}
\newtheorem{proposition}{Proposition}[section]
\newtheorem{lemma}{Lemma}[section]
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{example}{Example}[section]
\newtheorem{definition}[problem]{Definition}
\newcommand{\BEQA}{\begin{eqnarray}}
\newcommand{\EEQA}{\end{eqnarray}}
\usepackage{float}
%\newcommand{\define}{\stackrel{\triangle}{=}}
\theoremstyle{remark}
\usepackage{circuitikz}
\usepackage{tikz} % Required for inserting images
\graphicspath{{figs/}}

\title{\textbf{\underline{General Aptitude(GA)}}}
\author{}
\date{}


\begin{document}
\begin{figure}
 \centering
    \includegraphics[width=1\linewidth]{figs/0.png} 
\end{figure}
\small
\setlength{\tabcolsep}{8pt}
\renewcommand{\arraystretch}{1.2}
\maketitle

\Large\textbf{Q.1 - Q.5 Multiple choice question (MCQ), carry ONE mark each (for each wrong answer: - $\frac{1}{3}$)} 

\bigskip\bigskip\bigskip\bigskip\bigskip\bigskip
\Large\begin{tabular}{|p{1cm}|p{12.5cm}|}
\hline
\textbf{Q.1} & \textbf{The current population of a city is 11,02,500. If it has been increasing at the rate of 5\% per annum, what was its population 2 years ago?} \\
\hline
(A) & 9,92,500 \\
\hline
(B) & 9,95,006 \\
\hline
(C) & 10,00,000 \\
\hline
(D) & 12,51,506 \\
\hline
\end{tabular}

\hfill (GATE ST 2021) 
\\

\bigskip\bigskip\bigskip\bigskip\bigskip\bigskip

\Large\begin{tabular}{|p{1cm}|p{12.5cm}|}

\hline
\textbf{Q.2} & \textbf{p and q are positive integers and ratio $\frac{p}{q} + \frac{q}{p}=3$, then sum $\frac{p^2}{q^2} + \frac{q^2}{p^2}$ equals? } \bigskip \\
\hline
(A) & 3 \\
\hline
(B) & 7 \\
\hline
(C) & 9 \\
\hline
(D) & 11 \\
\hline
\end{tabular}

\hfill (GATE ST 2021)
\\

\Large\begin{tabular}{|p{1cm}|p{12.5cm}|}
\hline
\textbf{Q.3} & \includegraphics[width=0.3\textwidth]{3.png} \\ &\textbf{Least number of squares that must be added so that line P-Q becomes line of symmetry?}  \bigskip
\\
\hline
(A) & 4 \\
\hline
(B) & 3 \\
\hline
(C) & 6 \\
\hline
(D) & 7 \\
\hline
\end{tabular}

\bigskip
\hfill (GATE ST 2021)
\\
\begin{figure}
\huge\centering
    \huge\includegraphics[width=1\linewidth]{figs/0.png}
\end{figure}


\Large\begin{tabular}{|p{1cm}|p{12.5cm}|}
\hline

\textbf{Q.4} & \textbf{Nostalgia is to anticipation as \underline{\phantom{imagine}} to \underline{\phantom{imagine}} }\\ &
\textbf{Which one of the following options maintains a similar logical relation in the above sentence? }\\
\hline
(A) & Present, past \\
\hline
(B) & Future, past \\
\hline
(C) & Past, future \\
\hline
(D) & Future, present \\
\hline
\end{tabular}

\bigskip
\hfill (GATE ST 2021)
\\

\Large\begin{tabular}{|p{1cm}|p{12.5cm}|} 
\hline
\textbf{Q.5} & \textbf{Which of the sentences are grammatically correct?} \\   &(i)I woke up.\\  & (ii)I woked up.\\ & (iii)I was woken.\\ & (iv)I was wokened.\\
\hline
(A) & (i) and (ii) \\
\hline
(B) & (i) and (iii) \\
\hline
(C) & (ii) and (iii) \\
\hline
(D) & (i) and (iv) \\
\hline
\end{tabular}

\bigskip
\hfill (GATE ST 2021)
\\

\begin{figure}
\huge\centering
    \includegraphics[width=1\linewidth]{figs/0.png}
\end{figure}
 \newpage
 
 \begin{figure}
\huge\centering
    \includegraphics[width=1\linewidth]{figs/0.png}
\end{figure}

\Large\textbf{Q.6 - Q.10 Multiple choice question (MCQ), carry ONE mark each (for each wrong answer: - $\frac{2}{3}$)} 

\bigskip

\begin{tabular}{|p{1cm}|p{12.5cm}|}
\hline
\textbf{Q.6} &  \textbf{Given below are two statements and two conclusions.}\\ & Statement 1: All purple are green. \\ & All black are green. \\ & Conclusion I: Some black are purple. \\ & Conclusion II: No black is purple.\\
\hline
(A) & only conclusion I is correct. \\
\hline
(B) & only conclusion II is correct. \\
\hline
(C) & Either conclusion I or II is correct. \\
\hline
(D) & Both conclusion I and II are correct. \\
\hline
\end{tabular}

\bigskip
\hfill(GATE ST 2021)
\\

\newpage

\begin{tabular}{|p{1cm}|p{14cm}|}

\hline
\textbf{Q.7} & \textbf{Computers are ubiquitous. They are used to improve efficiency in almost all fields from agriculture to space exploration. Artificial intelligence (AI) is currently a hot topic. AI enables computers to learns, given enough training data. For humans, sitting in front of a computer for long hours can lead to health issues.}\\ &
Which of the following can be deduced from the above passage?\\ &
(i) Nowadays, computers are present in almost all places.\\ &
(ii) Computers cannot be used for solving problems in engineering.\\ &
(iii) For humans, there are both positive and negative effects of using computers.\\ &
(iv) Artificial intelligence can be done without data.\\ 

\hline
(A) & 3 \\
\hline
(B) & 7 \\
\hline
(C) & 9 \\
\hline
(D) & 11 \\
\hline
\end{tabular}

\bigskip
\hfill (GATE ST 2021)
\\
\begin{figure}
\huge\centering
    \includegraphics[width=1\linewidth]{figs/0.png}
\end{figure}

\begin{tabular}{|p{1cm}|p{12.5cm}|}

\hline
\textbf{Q.8} & \textbf{Consider a square sheet of side 1 unit. In the first step, it is cut along the main diagonal to get two triangles. In the next step, one of the cut triangles is revolved about its short edge to form a solid cone. The volume of the resulting cone, in cubic units, is \underline{\phantom{imagine}}  }
\bigskip \\


\hline
(A) & $\frac{\pi}{3}$ \\
\hline
(B) & $\frac{2\pi}{3}$ \\
\hline
(C) & $\frac{3\pi}{2}$ \\
\hline
(D) & $3\pi$ \\
\hline
\end{tabular}

\bigskip
\hfill (GATE ST 2021)

\newpage
\begin{figure}
\huge\centering
    \includegraphics[width=1\linewidth]{figs/0.png}
\end{figure}

\begin{tabular}{|p{1cm}|p{12.5cm}|}

\hline

\textbf{Q.9} & \includegraphics[width=1\linewidth]{figs/4.png}
\textbf{The number of minutes spent by two students, X and Y, exercising every day in a given week are shown in the bar chart below.}
\textbf{The number of days in the given week in which one of the students spent a minimum of 10\% more than the other student, on a given day, is}
\bigskip \\
\hline
(A) & 4 \\
\hline
(B) & 5 \\
\hline
(C) & 6 \\
\hline
(D) & 7 \\
\hline
\end{tabular}

\bigskip
\hfill (GATE ST 2021)
\\

\newpage
\begin{figure}
\huge\centering
    \includegraphics[width=1\linewidth]{figs/0.png}
\end{figure}
\begin{tabular}{|p{1cm}|p{12.5cm}|}

\hline
\textbf{Q.10} &   \includegraphics[width=1\linewidth]{figs/5.png}
\textbf{Corners are cut from an equilateral triangle to produce a regular convex hexagon as shown in the figure above. }
\textbf{The ratio of the area of the regular convex hexagon to the area of the original equilateral triangle is}

\bigskip
\\
\hline
(A) & $2:3$ \\
\hline
(B) & $3:4$ \\
\hline
(C) & $4:5$ \\
\hline
(D) & $5:6$ \\
\hline
\end{tabular}

\bigskip
\hfill (GATE ST 2021)
\\

\newpage
\begin{figure}
\huge\centering
    \includegraphics[width=1\linewidth]{figs/0.png}
\end{figure}

\newpage
\textbf{Q.1 -- Q.9 Multiple Choice Questions (MCQ), carry ONE mark each (for each wrong answer: -1/3).}

\bigskip\bigskip

\begin{tabular}{|p{1cm}|p{12.5cm}|}
\hline
\textbf{Q.1} & \textbf{Let X be a non-constant positive random variable such that E(X) = 9. Then which one of the following statements is true?}\\
\hline
(A) & $E\left(\frac{1}{X+1}\right) > 0.1$ and $P(X \geq 10) \leq 0.9$ \bigskip \\
\hline
(B) & $E\left(\frac{1}{X+1}\right) < 0.1$ and $P(X \geq 10) \leq 0.9$ \bigskip \\
\hline
(C) & $E\left(\frac{1}{X+1}\right) > 0.1$ and $P(X \geq 10) > 0.9$ \bigskip\\
\hline
(D) & $E\left(\frac{1}{X+1}\right) < 0.1$ and $P(X \geq 10) > 0.9$ \bigskip\\
\hline
\end{tabular}

\bigskip\bigskip
\hfill (GATE ST 2021)
\\

\begin{tabular}{|p{1cm}|p{12.5cm}|}
\hline
\textbf{Q.2} & \textbf{Let $\{W(t)\}_{t \geq 0}$ be a standard Brownian motion. Then the variance of W(1)W(2) equals} \\
\hline
(A) & 1 \\
\hline
(B) & 2 \\ 
\hline
(C) & 3 \\
\hline
(D) & 4 \\
\hline

\end{tabular}

\hfill (GATE ST 2021)
\\

\newpage
\begin{figure}
\huge\centering
    \includegraphics[width=1\linewidth]{figs/0.png}
\end{figure}

\begin{tabular}{|p{1cm}|p{12.5cm}|}
\hline
\textbf{Q.3} & \textbf{Let $X_1, X_2, \dots, X_n$ be a random sample of size $n$ $(\geq 2)$ from a distribution having the probability density function}
 where $\theta \in (0, \infty)$. Then the method of moments estimator of $\theta$ equals\\ 
 \hline
 (A) &  $\frac{1}{2 \overline{X}}$ \bigskip \\
\hline
(B) & $\frac{2}{\overline{X}}$ \bigskip \\
\hline
(C) & $\frac{n}{\sum_{i=1}^n X_i}$ \bigskip \\
\hline
(D) & $1 - 2\left(\frac{1}{n}\sum_{i=1}^n X_i \right)$ \bigskip \\
\hline
\end{tabular}

\bigskip
\hfill (GATE ST 2021)
\\

\begin{tabular}{|p{1cm}|p{12.5cm}|}
\hline
 
\textbf{Q.4} & \textbf{Let $\{X_1, X_2, \dots, X_n\}$ be a realization of a random sample of size $n$ $(\geq 2)$ from a $N(\mu, \sigma^2)$ distribution, where $-\infty < \mu < \infty$ and $\sigma > 0$. Which of the following statements is/are true? }

P: $95\%$ confidence interval of $\mu$ based on $\{X_1, X_2, \dots, X_n\}$ is unique when $\sigma$ is known.  

Q: $95\%$ confidence interval of $\mu$ based on $\{X_1, X_2,\dots, X_n\}$ is \textit{not} unique when $\sigma$ is unknown.
\\
\hline
(A) & P only \\
\hline
(B) & Q only \\
\hline
(C) & Both P and Q \\
\hline
(D) & Neither P nor Q \\ 
\hline
\end{tabular}

\bigskip
\hfill (GATE ST 2021)
\\

\newpage

\begin{figure}
\huge\centering
    \includegraphics[width=1\linewidth]{figs/0.png}
\end{figure}

\begin{tabular}{|p{1cm}|p{12.5cm}|}
\hline
\textbf{Q.5} &\textbf{ Let $X_1, X_2, \dots, X_n$ be a random sample of size $n$ $(\geq 2)$ from a $N(0, \sigma^2)$ distribution. For a given $\sigma > 0$, let $f_0$ denote the joint probability density function of $(X_1, X_2, \dots, X_n)$ and $S = \{f_0 : \sigma > 0\}$. Let $T_1 = \sum_{i=1}^n X_i$ and $T_2 = \sum_{i=1}^n X_i^2$. For any positive integer $v$ and any $a \in (0,1)$, let $\chi^2_{v,a}$ denote the $(1-a)$-th quantile of the central chi-square distribution with $v$ degrees of freedom. Consider testing $H_0 : \sigma = 1$ against $H_1 : \sigma > 1$ at level a. Then which one of the following statements is true? } \\ 
\hline

(A) & S has a monotone likelihood ratio in $T_1$ and $H_0$ is rejected if $T_1 > \chi^2_\alpha$ \\
\hline
(B) & S has a monotone likelihood ratio in $T_1$ and $H_0$ is rejected if $T_1 > \chi^2_{n,1-\alpha}$ \\
\hline
(C) & S has a monotone likelihood ratio in $T_2$ and $H_0$ is rejected if $T_2 > \chi^2_{\alpha}$ \\ 
\hline
(D) & S has a monotone likelihood ratio in $T_2$ and $H_0$ is rejected if $T_2 > \chi^2_{n,1-\alpha}$ \\
\hline
\end{tabular}

\bigskip
\hfill (GATE ST 2021)
\\
\newpage
\begin{figure}
\centering
    \includegraphics[width=0.7\linewidth]{figs/0.png}
\end{figure}

\textbf{Q.6 \textminus Q.7 Multiple Choice Questions (MCQ), carry TWO marks each (for each wrong answer: $-2/3$)}

\bigskip

\begin{tabular}{|p{1cm}|p{16.5cm}|}
\hline
\textbf{Q.6} & Let $X$ and $Y$ be two random variables such that $P_{11} + P_{10} + P_{01} + P_{00} =1$, where $p_{ij} = P(X = i, Y = j)$, $i, j = 0,1$. Suppose that a realization of a random sample of size 60 from the joint distribution of $(X,Y)$ gives
$$
N_{11} = 10, \quad N_{10} = 20, \quad N_{01} = 20, \quad N_{00} = 10,
$$
where $N_{ij}$ denotes the frequency of $(i,j)$ for $i,j=0,1$. If the chi-square test of independence is used to test
$$
H_0:p_{ij} = p_{i}\cdot p_{j}\quad\text{for} i,j=0,1   \text{against}\quad H_1 : p_{ij} \neq p_{i.} \cdot p_{.j}   \text{for at least one }  (i,j),$$
where $p_{i.} = p_{i0} + p_{i1}$ and $p_{.j} = p_{0j} + p_{1j}$, then which one of the following statements is true? \\
\hline

(A) & Under $H_0$, the test statistic follows a central chi-square distribution with 1 degree of freedom and the observed value of the test statistic is $\frac{3}{20}$.\\
\hline
(B) & Under $H_0$, the test statistic follows a central chi-square distribution with 3 degrees of freedom and the observed value of the test statistic is $\frac{20}{3}$.\\
\hline
(C) & Under $H_0$, the test statistic follows a central chi-square distribution with 1 degree of freedom and the observed value of the test statistic is $\frac{16}{3}$.\\
\hline
(D) & Under $H_0$, the test statistic follows a central chi-square distribution with 3 degrees of freedom and the observed value of the test statistic is $\frac{3}{16}$.\\
\hline
\end{tabular}    

\hfill (GATE ST 2021)

\begin{tabular}{|p{1cm}|p{16cm}|}
\hline
\textbf{Q.7}  & Let the joint distribution of (X, Y) be bivariate normal with mean vector $\boldsymbol{\mu}$ and variance-covariance matrix $\Sigma$,
$$
\boldsymbol{\mu} = \begin{bmatrix} 0 \\ 0 \end{bmatrix}, \quad 
\Sigma = \begin{bmatrix}
1 & \rho \\
\rho & 1
\end{bmatrix}, \quad \text{where } -1 < \rho < 1.
$$

Let $\Phi_{\rho}(0,0) = P(X \leq 0, Y \leq 0)$. Then the Kendall's tau coefficient between $X$ and $Y$ equals: \\
\hline
(A) & $4\Phi_{\rho}(0,0) - 1$ \\
\hline
(B) & $4\Phi_{\rho}(0,0)$ \\
\hline
(C) & $4\Phi_{\rho}(0,0) + 1$ \\
\hline
(D) & $\Phi_{\rho}(0,0)$ \\
\hline
\end{tabular}


\hfill (GATE ST 2021)
 \newpage
\begin{figure}
\huge\centering
    \includegraphics[width=1\linewidth]{figs/0.png}
\end{figure}
 
\begin{tabular}{|p{1cm}|p{12.5cm}|}
\hline

\textbf{Q.8} & Consider the simple linear regression model
$$ Y_i = \beta_0 + \beta_1 x_i + \varepsilon_i,\ i=1,2,...,n\ (n\geq3),$$
where $\beta_0$ and $\beta_1$ are unknown parameters and $\varepsilon_i$'s are independent and identically distributed random variables with mean zero and finite variance $\sigma^2>0$. Suppose that $\hat{\beta}_0$ and $\hat{\beta}_1$ are the OLS estimators of $\beta_0$ and $\beta_1$, respectively. Define  $\bar{x} = \frac{1}{n}\sum_{i=1}^n x_i$, \quad $S_1 = \sum_{i=1}^n (x_i-\bar{x})^2$, \quad $S_2=\sum_{i=1}^n Y_i(x_i-\bar{x})$, \quad where $Y_i$ is the observed value of $Y_i$.
Then for a real constant $c$, the variance of $\hat{\beta}_0$ + c is
\\
\hline

(A) & $\frac{\sigma^2}{n} + c^2 \frac{\sigma^2}{S_1}$\\
\hline
(B) & $\frac{\sigma^2}{n} + c^2 \frac{\sigma^2}{\bar{x}^2}$\\
\hline
(C) & $2\frac{\sigma^2}{n}$\\
\hline
(D) & $\frac{\sigma^2}{\bar{x}^2} + c^2$\\
\hline
\end{tabular}

\bigskip
\hfill (GATE ST 2021)
\\

\begin{tabular}{|p{1cm}|p{12.5cm}|}
\hline
\textbf{}9 & 
Let $X_1, X_2, X_3, Y_1, Y_2, Y_3, Y_4$ be independent random vectors such that $X_i$ follows $N_4(0, \Sigma_1)$ distribution for $i=1,2,3$, and $Y_j$ follows $N_4(0, \Sigma_2)$ for $j=1,2,3,4$, where $\Sigma_1$ and $\Sigma_2$ are positive definite matrices. Further, let
$Z = \Sigma_1^{-1/2} X X^T \Sigma_1^{-1/2} + \Sigma_2^{-1/2} Y Y^T \Sigma_2^{-1/2}$,
where $X = [X_1\ X_2\ X_3]$ is a $4\times3$ matrix, $Y = [Y_1\ Y_2\ Y_3\ Y_4]$ is $4\times4$ and $X^T$, $Y^T$ denote transposes.
If $W_m(n,\Sigma)$ denotes a Wishart distribution of order $m$ with $n$ degrees of freedom and variance-covariance matrix $\Sigma$ and $I_n$ is the $n\times n$ identity matrix, then which is true? \\
\hline
(A) & $Z$ follows $W_4(7, I_4)$ \\
\hline
(B) & $Z$ follows $W_4(4, I_4)$ \\
\hline
(C) & $Z$ follows $W_7(4, I_7)$ \\
\hline
(D) & $Z$ follows $W_7(7, I_7)$ \\
\hline
\end{tabular}

\bigskip
\hfill (GATE ST 2021)
\\
\newpage

\begin{figure}
\huge\centering
    \includegraphics[width=1\linewidth]{figs/0.png}
\end{figure}
\textbf{Q.10 -- Q.25 Numerical Answer Type (NAT), carry ONE mark each (no negative marks).}

\bigskip

\begin{tabular}{|p{1cm}|p{14cm}|}
\hline
\textbf{Q.10} &
$$
\lim_{n \to \infty} (2^n \sin^2 \tfrac{1}{2^n} - n \cos^2 \tfrac{1}{2^n}) $$
equals \\
\hline
\end{tabular}

\bigskip
\hfill (GATE ST 2021)
\\

\begin{tabular}{|p{1cm}|p{14cm}|}
\hline
\textbf{Q.11} &
Let 
$$
I = \int_0^1 \int_0^{\sqrt{2 - x^2}} \frac{y}{\sqrt{x^2 + y^2}} dy\ dx
$$
Then the value of $e^{I+1}$ equals \textit{(round off to 2 decimal places).} \\
\hline
\end{tabular}

\bigskip
\hfill (GATE ST 2021)
\\

\begin{tabular}{|p{1cm}|p{14cm}|}
\hline

\textbf{Q.12} &
Let $A = \begin{bmatrix}
0 & 0 & 1 \\
0 & 1 & 0 \\
1 & 0 & 0
\end{bmatrix}$
and $I_3$ be the $3\times 3$ identity matrix. Then the nullity of $5A(I_3 + A + A^{2})$ equals \\
\hline
\end{tabular}

\bigskip
\hfill (GATE ST 2021)
\\

\begin{tabular}{|p{1cm}|p{14cm}|}
\hline
\textbf{Q.13} &
Let $A$ be the $2\times 2$ real matrix having eigenvalues $1$ and $-1$, with corresponding eigenvectors
$\begin{bmatrix} \sqrt{3} \\ 1 \end{bmatrix}$ and $\begin{bmatrix} -1\\ 2 \end{bmatrix}$, respectively. If 
$A^{2021} = \begin{bmatrix} a & b\\ c & d \end{bmatrix}$ then $a+b+c+d$ equals \textit{(round off to 2 decimal places).} \\ 
\hline
\end{tabular}

\bigskip
\hfill (GATE ST 2021)

\begin{tabular}{|p{1cm}|p{14cm}|}
\hline
\textbf{Q.14} &
Let A and B be two events such that $P(B) = \frac{3}{4}$ and $P(A \cup B^C) = \frac{1}{2}$. If A and B are independent, then P(A) equals \textit{(round off to 2 decimal places).}\\
\hline
\end{tabular}

\hfill (GATE ST 2021)

\newpage

\begin{figure}
\huge\centering
    \includegraphics[width=1\linewidth]{figs/0.png}
\end{figure}
\begin{tabular}{|p{1cm}|p{14cm}|}
\hline
\textbf{Q.15} &
A fair die is rolled twice independently. Let $X$ and $Y$ denote the outcomes of the first and second roll, respectively. Then $E(X + Y \mid (X-Y)^2 = 1)$ equals \\
\hline
 \end{tabular}
 
\bigskip
\hfill (GATE ST 2021)
\\

\begin{tabular}{|p{1cm}|p{14cm}|}
\hline
\textbf{Q.16} &
Let $X$ be a random variable having distribution function
$$
F(x) = 
\begin{cases}
0 & x < 1\\\begin{tabular}{|p{1cm}|p{12.5cm}|}
\hline
\textbf{Q.6} &  \textbf{Given below are two statements and two conclusions.}\\ & Statement 1: All purple are green. \\ & All black are green. \\ & Conclusion I: Some black are purple. \\ & Conclusion II: No black is purple.\\
\hline
(A) & only conclusion I is correct. \\
\hline
(B) & only conclusion II is correct. \\
\hline
(C) & Either conclusion I or II is correct. \\
\hline
(D) & Both conclusion I and II are correct. \\
\hline
\end{tabular}

\bigskip
\hfill(GATE ST 2021)
\\

a & 1 < x < 2\\
c & 2 < x < 3\\
1 & x \geq 3
\end{cases}
$$
where $a$ and $c$ are appropriate constants. Let $A_n = [1 + \frac{1}{n}, 3 - \frac{1}{n}]$, $n \geq 1$, and $A = \bigcup_{n \geq 1} A_n$. If $P(X \leq 1) = \frac{1}{5}$ and $E(X) = 3$, then $P(X \in A)$ equals \textit{(round off to 2 decimal places).} \\
\hline
\end{tabular}

\bigskip
\hfill (GATE ST 2021)
\\

\begin{tabular}{|p{1cm}|p{14cm}|}
\hline
\textbf{Q.17} &
If the marginal probability density function of the $k$th order statistic of a random sample of size $8$ from a uniform distribution on $[0,2]$ is
$$
f(x) = 
\begin{cases}
\frac{7}{32}x(2-x), & 0 < x < 2 \\
0, & \text{otherwise}
\end{cases}
$$
then $k$ equals\\
\hline
\end{tabular}

\bigskip
\hfill (GATE ST 2021)
\\

\begin{tabular}{|p{1cm}|p{14cm}|}
\hline
\textbf{Q.18} &
For $a > 0$, let $\{X_n^{(\alpha)}\}_{n \geq 1}$ be a sequence of independent random variables such that $P(X_n^{(\alpha)} = 1) = \frac{1}{n^\alpha} = 1 - P(X_n^{(\alpha)} = 0)$. Let $S = \{\alpha > 0 : X_n^{(\alpha)} \to 0 \text{ almost surely as } n \to \infty\}$. Then the infimum of $S$ equals \textit{(round off to 2 decimal places).} \\
\hline
\end{tabular}

\bigskip
\hfill (GATE ST 2021)
\\
\newpage
\begin{tabular}{|p{1cm}|p{14cm}|}
\hline
\textbf{Q.19} &
Let $\{X_n\}_{n \geq 1}$ be a sequence of independent and identically distributed random variables each having uniform distribution on $[0,2]$. For $n \geq 1$, let
$$
Z_n = -\log_e \left( \frac{1}{n} \sum_{i=1}^n (2 - X_i) \right)
$$
Then, as $n \to \infty$, the sequence $\{Z_n\}_{n \geq 1}$ converges almost surely to \textit{(round off to 2 decimal places).}\\
\hline
\end{tabular}

\bigskip
\hfill (GATE ST 2021)
\\

\begin{tabular}{|p{1cm}|p{14cm}|}
\hline
\textbf{Q.20} &
Let $\{X_n\}_{n \geq 0}$ be a time-homogeneous discrete time Markov chain with state space $\{0,1\}$ and transition probability matrix
$$
\begin{bmatrix}
0.25 & 0.75 \\
0.75 & 0.25
\end{bmatrix}
$$
If $P(X_0 = 0) = P(X_0 = 1) = 0.5$, then
$$
\sum_{k=1}^{100} E\left[(X_{2k})(X_{2k})\right]
$$
equals\\
\hline
\end{tabular}

\bigskip
\hfill (GATE ST 2021)
\\

\begin{tabular}{|p{1cm}|p{14cm}|}
\hline
\textbf{Q.21} &
Let $\{0,2\}$ be a realization of a random sample of size 2 from a binomial distribution with parameters 2 and $p$, where $p \in (0,1)$. To test $H_0: p = \frac{1}{2}$ against $H_1: p = \frac{1}{2}$, the observed value of the likelihood ratio test statistic equals \textit{(round off to 2 decimal places).}\\
\hline
\end{tabular}

\bigskip
\hfill (GATE ST 2021)
\\
\begin{tabular}{|p{1cm}|p{14cm}|}
\hline
\textbf{Q.22} &
Let $X$ be a random variable having the probability density function
$$
f(x) = 
\begin{cases}
\frac{13}{3}(1-x)(9-x), & 0 < x < 1\\
0, & \text{otherwise}
\end{cases}
$$
Then $E[X(X^2 - 15X + 27)]$ equals \textit{(round off to 2 decimal places).}\\
\hline
\end{tabular}

\bigskip
\hfill (GATE ST 2021)
\\
\begin{tabular}{|p{1cm}|p{14cm}|}
\hline
\textbf{Q.23} &
Let $(Y, X_1, X_2)$ be a random vector with mean vector
$$
\begin{bmatrix}
5 \\ 2 \\ 0
\end{bmatrix}
$$
and variance-covariance matrix
$$
\begin{bmatrix}
10 & 0.5 & -0.5 \\
0.5 & 7 & 1.5 \\
-0.5 & 1.5 & 2
\end{bmatrix}
$$
Then the value of the multiple correlation coefficient between $Y$ and its best linear predictor on $X_1$ and $X_2$ equals \textit{(round off to 2 decimal places).}\\
\hline
\end{tabular}

\bigskip
\hfill (GATE ST 2021)
\\
\begin{tabular}{|p{1cm}|p{14cm}|}
\hline
\textbf{Q.24} &
Let $X_1, X_2$, and $X_3$ be a random sample from a bivariate normal distribution with unknown mean vector $\mu$ and unknown variance-covariance matrix $\Sigma$, which is a positive definite matrix. The p-value corresponding to the likelihood ratio test for testing $H_0: \mu = 0$ against $H_1: \mu \neq 0$ based on the realization $\{(2,2), (2,2), (5,4)\}$ of the random sample equals \textit{(round off to 2 decimal places).}\\
\hline
\end{tabular}

\bigskip
\hfill (GATE ST 2021)
\\
\begin{tabular}{|p{1cm}|p{14cm}|}
\hline
\textbf{Q.25} &
Let $Y_i = \alpha + \beta x_i + \varepsilon_i,\ i = 1,2,3$, where $x_i$'s are fixed covariates, $\alpha$ and $\beta$ are unknown parameters and $\varepsilon_i$'s are independent and identically distributed random variables with mean zero and finite variance. Let $\hat{\alpha}$ and $\hat{\beta}$ be the ordinary least squares estimators of $\alpha$ and $\beta$, respectively. Given the following observations:

\begin{center}
\begin{tabular}{|c|c|c|c|}
\hline
$Y_i$ & 8.62 & 26.86 & 54.02 \\
\hline
$x_i$ & 3.29 & 21.53 & 48.69 \\
\hline
\end{tabular}
\end{center}

the value of $\hat{\alpha} + \hat{\beta}$ equals \textit{(round off to 2 decimal places).}\\
\hline
\end{tabular}

\bigskip
\hfill (GATE ST 2021)
\\

\textbf{Q.26 -- Q.43 Multiple Choice Question (MCQ), carry TWO marks each (for each wrong answer: $-\frac{2}{3}$).}
\begin{tabular}{|p{1cm}|p{14cm}|}
\hline
\textbf{Q.26} &
Let $f: \mathbb{R} \to \mathbb{R}$ be defined by
$$
f(x) = 
\begin{cases}
x^{3} \sin x, & x=0 \text{ or } x \text{ is irrational}, \\
\frac{p^{3}}{q^{3}}, & x = \frac{p}{q},\ p \in \mathbb{Z} \setminus \{0\}, q \in \mathbb{N},\ \gcd(p,q) = 1,
\end{cases}
$$
where $R$ denotes the set of all real numbers, $\mathbb{Z}$ denotes the set of all integers, $N$ denotes the set of positive integers, and $\gcd(p,q)$ denotes the greatest common divisor of $p$ and $q$. Then which one of the following statements is true?\\
\hline

(A) & $f$ is not continuous at $0$.\\
\hline
(B) & $f$ is not differentiable at $0$.\\
\hline
(C) & $f$ is differentiable at $0$ and the derivative of $f$ at $0$ equals $0$.\\
\hline
(D) & $f$ is differentiable at $0$ and the derivative of $f$ at $0$ equals $1$.\\
\hline
\end{tabular}

\bigskip
\hfill (GATE ST 2021)
\\
\begin{tabular}{|p{1cm}|p{14cm}|}
\hline
\textbf{Q.27} &
Let $f: [0, \infty) \to \mathbb{R}$ be a function. Then which one of the following statements is true?\\
\hline

(A) & If $f$ is bounded and continuous, then $f$ is uniformly continuous.\\
\hline
(B) & If $f$ is uniformly continuous, then $\lim_{x \to \infty} f(x)$ exists.\\
\hline
(C) & If $f$ is uniformly continuous, then the function $g(x) = f(x) \sin x$ is also uniformly continuous.\\
\hline
(D) & If $f$ is continuous and $\lim_{x \to \infty} f(x)$ is finite, then $f$ is uniformly continuous.\\
\hline
\end{tabular}
\bigskip
\hfill (GATE ST 2021)
\\
\begin{tabular}{|p{1cm}|p{14cm}|}
\hline
\textbf{Q.28} &
Let $f: {R} \xrightarrow{}{R}$ be a differentiable function such that $f(0) = 0$ and
$$
f'(x) + 2 f(x) > 0, \quad \forall x \in \mathbb{R},
$$
where $f'$ denotes the derivative of $f$. Then which one of the following statements is true? \\
\hline

(A) & $f(x) > 0$, for all $x > 0$ and $f(x) < 0$, for all $x < 0$.\\
\hline
(B) & $f(x) < 0$, for all $x \neq 0$.\\ 
\hline
(C) & $f(x) > 0$, for all $x \neq 0$.\\
\hline
(D) & $f(x) < 0$, for all $x > 0$ and $f(x) > 0$, for all $x < 0$.\\
\hline
\end{tabular}
\bigskip
\hfill (GATE ST 2021)
\\
\begin{tabular}{|p{1cm}|p{14cm}|}
\hline
\textbf{Q.29} &
Let $M$ be the collection of all $3 \times 3$ real symmetric positive definite matrices. Consider the set
$$
S = \{ A \in M : A^{50} - A^{48} = 0 \},
$$
where $0$ denotes the $3 \times 3$ zero matrix. Then the number of elements in $S$ equals\\
\hline

(A) & 0\\
\hline
(B) & 1\\
\hline
(C)] & 8\\
\hline
(D) &  $2^{8}$\\
\hline
\end{tabular}
\bigskip
\hfill (GATE ST 2021)
\\
\begin{tabular}{|p{1cm}|p{14cm}|}
\hline
\textbf{Q.30} &
Let $A$ be a $3 \times 3$ real matrix such that $I_3 + A$ is invertible and let
$$
B = (I_3 + A)^{-1} (I_3 - A),
$$
where $I_3$ denotes the $3 \times 3$ identity matrix. Then which one of the following statements is true?\\
\hline

(A) & If $B$ is orthogonal, then $A$ is invertible.\\
\hline
(B) & If $B$ is orthogonal, then all the eigenvalues of $A$ are real.\\
\hline
(C) & If $B$ is skew-symmetric, then $A$ is orthogonal.\\
\hline
(D) & If $B$ is skew-symmetric, then the determinant of $A$ equals $-1$.\\
\hline
\end{tabular}

\bigskip
\hfill (GATE ST 2021)
\\
\begin{tabular}{|p{1cm}|p{14cm}|}
\hline
\textbf{Q.31} &
Let $X$ be a random variable having Poisson distribution such that $E(X^2) = 110$. Then which one of the following statements is NOT true?\\
\hline

(A) & $E(X) = 10$\\
\hline
(B) & $E[(X+1)^{n-1}] = E(X)$, for all $n = 1, 2, 3, \dots$\\
\hline
(C) & $P(X \text{ is even}) = \frac{1 + e^{-20}}{2}$\\
\hline
(D) & $P(X = k) < P(X = k+1)$, for $k = 0,1,\dots, 8$\\
\hline
(E) & $P(X = k) > P(X = k+1)$, for $k = 10, 11, \dots$\\
\hline
\end{tabular}

\bigskip
\hfill (GATE ST 2021)
\\
\begin{tabular}{|p{1cm}|p{14cm}|}
\hline
\textbf{Q.32} &
Let $X$ be a random variable having uniform distribution on $\left(-\frac{\pi}{2}, \frac{\pi}{2}\right)$. Then which one of the following statements is NOT true?\\
\hline

(A) & $Y = \cot X$ follows standard Cauchy distribution\\
\hline
(B) & $Y = \tan X$ follows standard Cauchy distribution\\
\hline
(C) & $Y = -\log_e\left( \frac{1+X}{1 - X} \right)$ has moment generating function $M(t) = \frac{1}{1 - t}$, for $t < 1$\\
\hline
(D) & $Y = -2 - 2 \log_e \left( \frac{1+X}{1-X}\right)$ follows central chi-square distribution with one degree of freedom\\
\hline
\end{tabular}

\bigskip
\hfill (GATE ST 2021)
\\
\begin{tabular}{|p{1cm}|p{14cm}|}
\hline
\textbf{Q.33} &
Let $\Omega = \{1,2,3,\dots\}$ represent the collection of all possible outcomes of a random experiment with probabilities $P(\{n\}) = a_n$ for $n \in \Omega$. Then which one of the following statements is NOT true?\\
\hline

(A) & $\lim_{n \to \infty} a_n = 0$\\
\hline
(B) & $\sum_{n=1}^\infty \sqrt{a_n}$ converges\\
\hline
(C) & For any positive integer $k$, there exist $k$ disjoint events $A_1, A_2, \dots, A_k$ such that $P\left(\bigcup_{i=1}^k A_i\right) < 0.001$\\ 
\hline
(D) & There exists a sequence $\{A_i\}_{i\geq 1}$ of strictly increasing events such that $P\left(\bigcup_{i=1}^\infty A_i\right) < 0.001$\\
\hline
\end{tabular}

\bigskip
\hfill (GATE ST 2021)
\\
\begin{tabular}{|p{1cm}|p{14cm}|}
\hline
\textbf{Q.34} &
Let $(X,Y)$ have the joint probability density function
$$
f_{X,Y}(x,y) = 4(x + y)^3, \quad x > 1, y > 1,
$$
and zero otherwise. Then which one of the following statements is NOT true?\\
\hline

(A) & The probability density function of $X + Y$ is
$$
f_{X+Y}(z) = \frac{4}{73} z^3 (z - 2), \quad z > 2,
$$
and zero otherwise.\\
\hline
(B) & $P(X + Y > 4) = \frac{3}{4}$\\
\hline
(C) & $E(X + Y) = 4 \log_e 2$ \\
\hline
(D) & $E(Y \mid X = 2) = 4$\\
\hline
\end{tabular}

\bigskip
\hfill (GATE ST 2021)
\\
\begin{tabular}{|p{1cm}|p{14cm}|}
\hline
\textbf{Q.35} &
Let $X_1, X_2$, and $X_3$ be three uncorrelated random variables with common variance $\sigma^2 < \infty$. Let
$$
Y_1 = 2X_1 + X_2 + X_3, \quad Y_2 = X_1 + 2X_2 + X_3, \quad \text{and} \quad Y_3 = X_1 + X_2 + 2X_3.
$$
Then which of the following statements is/are true?

\begin{itemize}
\item[(P)] The sum of eigenvalues of the variance-covariance matrix of $(Y_1, Y_2, Y_3)$ is $18 \sigma^2$.
\item[(Q)] The correlation coefficient between $Y_1$ and $Y_2$ equals that between $Y_2$ and $Y_3$.
\end{itemize}\\
\hline

(A) & P only\\
\hline
(B) & Q only\\
\hline
(C) & Both P and Q\\
\hline
(D) & Neither P nor Q\\
\hline
\end{tabular}

\bigskip
\hfill (GATE ST 2021)
\\
\begin{tabular}{|p{1cm}|p{14cm}|}
\hline
\textbf{Q.36} &
Let $\{X_n\}_{n \geq 0}$ be a time-homogeneous discrete time Markov chain with either finite or countable state space $S$. Then which one of the following statements is true?\\
\hline

(A) & There is at least one recurrent state.\\
\hline
(B) & If there is an absorbing state, then there exists at least one stationary distribution.\\
\hline
(C) & If all the states are positive recurrent, then there exists a unique stationary distribution.\\
\hline
(D) & If $\{X_n\}_{n \geq 0}$ is irreducible, $S = \{1,2\}$ and $[\pi_1 \ \pi_2]$ is a stationary distribution, then $\lim_{n \to \infty} P(X_n = i \mid X_0 = i) = \pi_i$ for $i=1,2$.\\
\hline
\end{tabular}

\bigskip
\hfill (GATE ST 2021)
\\
\begin{tabular}{|p{1cm}|p{14cm}|}
\hline
\textbf{Q.37} &
Let customers arrive at a departmental store according to a Poisson process with rate 10. Further, suppose that each arriving customer is either a male or a female with probability $\frac{1}{2}$ each, independent of all other arrivals. Let $N(t)$ denote the total number of customers who have arrived by time $t$. Then which one of the following statements is NOT true?\\
\hline

(A) & If $S_2$ denotes the time of arrival of the second female customer, then $P(S_2 \leq 1) = 25 \int_0^1 s e^{-5 s} ds$.\\
\hline
(B) & If $M(t)$ denotes the number of male customers who have arrived by time $t$, then $P(M = 0 \mid M(1) = 1) = \frac{1}{3}$.\\
\hline
(C) & $E[(N(t))^2] = 100 t^2 + 10 t$.\\
\hline
(D) & $E[N(t) N(2t)] = 200 t^2 + 10 t$.\\
\hline
\end{tabular}

\bigskip
\hfill (GATE ST 2021)
\\
\begin{tabular}{|p{1cm}|p{14cm}|}
\hline
\textbf{Q.38} &
Let $X_{(1)} < X_{(2)} < X_{(3)} < X_{(4)} < X_{(5)}$ be the order statistics corresponding to a random sample of size 5 from a uniform distribution on $[0,\theta]$, where $\theta \in (0, \infty)$. Then which of the following statements is/are true?

\begin{itemize}
\item[(P)] $3 X_{(2)}$ is an unbiased estimator of $\theta$.
\item[(Q)] The variance of $E[2 X_{(3)} \mid X_{(5)}]$ is less than or equal to the variance of $2 X_{(3)}$.
\end{itemize}\\
\hline
(A) & P only\\
\hline
(B) &  Q only\\
\hline
(C) & Both P and Q\\
\hline
(D) & Neither P nor Q\\
\hline
\end{tabular}

\bigskip
\hfill (GATE ST 2021)
\\
\begin{tabular}{|p{1cm}|p{14cm}|}
\hline
\textbf{Q.39} &
Let $X_1, X_2, \ldots, X_n$ be a random sample of size $n$ ($\geq 2$) from a distribution having the probability density function
$$
f(x; \theta) = \theta e^{-\theta x}, \quad x > 0,
$$
and zero otherwise, where $\theta \in (0, \infty)$. Let $X_{(1)} = \min \{ X_1, X_2, \ldots, X_n \}$ and $T = \sum_{i=1}^n X_i$. Then $E(X_{(1)} \mid T)$ equals\\
\hline
(A) & $\frac{T}{n^2}$ \\
\hline
(B) & $\frac{T}{n}$ \\
\hline
(C) & $\frac{(n+1) T}{2 n}$ \\
\hline
(D) & $\frac{(n+1)^2 T}{4 n^2}$\\
\hline
\end{tabular}

\bigskip
\hfill (GATE ST 2021)
\\
\begin{tabular}{|p{1cm}|p{14cm}|}
\hline
\textbf{Q.40} &
Let $X_1, X_2, \ldots, X_n$ be a random sample of size $n$ ($\geq 2$) from a uniform distribution on $[-\theta, \theta]$, where $\theta \in (0, \infty)$. Let $X_{(1)} = \min \{ X_1, X_2, \ldots, X_n \}$ and $X_{(n)} = \max \{ X_1, X_2, \ldots, X_n \}$. Then which of the following statements is/are true?

\begin{itemize}
\item[(P)] $(X_{(1)}, X_{(n)})$ is a complete statistic.
\item[(Q)] $X_{(n)} - X_{(1)}$ is an ancillary statistic.
\end{itemize}\\
\hline
(A) & P only\\
\hline
(B) & Q only\\
\hline
(C) & Both P and Q\\
\hline
(D) & Neither P nor Q\\
\hline
\end{tabular}

\bigskip
\hfill (GATE ST 2021)
\\
\begin{tabular}{|p{1cm}|p{14cm}|}
\hline
\textbf{Q.41} &
Let $\{X_n\}_{n \geq 1}$ be a sequence of independent and identically distributed random variables having common distribution function $F(\cdot)$. Let $a < b$ be two real numbers such that $F(x) = 0$ for all $x \leq a$, $0 < F(x) < 1$ for all $a < x < b$, and $F(x) = 1$ for all $x \geq b$. Let $S_n(x)$ be the empirical distribution function at $x$ based on $X_1, X_2, \ldots, X_n$, $n \geq 1$. Then which one of the following statements is NOT true?\\
\hline
(A) & $\displaystyle \Pr\left(\lim_{n \to \infty} \sup_{-\infty < x < \infty} |S_n(x) - F(x)| = 0 \right) = 1$ \\
\hline
(B) & For fixed $x \in (a,b)$ and $t \in (-\infty, \infty)$,
$$
\lim_{n \to \infty} \Pr\left(\sqrt{n} \frac{|S_n(x) - F(x)|}{\sqrt{F(x)(1 - F(x))}} \leq t\right) = \Pr(Z \leq t), 
$$
    where $Z$ is the standard normal random variable. \\
\hline
(C) & The covariance between $S_n(x)$ and $S_n(y)$ equals $\frac{F(x)(1 - F(y))}{n}$ for all $n \geq 2$ and for fixed $-\infty < x,y < \infty$.\\
\hline
(D) & If $Y_n = \sup_{-\infty < x < \infty} (S_n(x) - F(x))^2$, then $\{4n Y_n\}_{n \geq 1}$ converges in distribution to a central chi-square random variable with 2 degrees of freedom.\\
\hline
\end{tabular}

\bigskip
\hfill (GATE ST 2021)
\\
\begin{tabular}{|p{1cm}|p{14cm}|}
\hline
\textbf{Q.42} &
Let the joint distribution of random variables $X_1, X_2, X_3$ and $X_4$ be $N_4(\mu, \Sigma)$, where
$$
\mu = \begin{bmatrix} 1 \\ 1 \\ 0 \\ 2 \end{bmatrix}
\quad \text{and} \quad
\Sigma =
\begin{bmatrix}
2 & 0 & 0.2 & 0 \\
0 & 2 & 0 & 0.2 \\
0.2 & 0 & 1 & 0 \\
0 & 0.2 & 0 & 1
\end{bmatrix}.
$$
Then which one of the following statements is true?\\
\hline
(A) & $(X_1 + X_2)^2 + (X_3 + X_4 - 1)^2$ follows a central chi-square distribution with 2 degrees of freedom.\\
\hline
(B) & $(X_1 + X_3 - 1)^2 + (X_2 + X_4 - 1)^2$ follows a central chi-square distribution with 2 degrees of freedom.\\
\hline
(C) & $E\left(\frac{X_1 + X_2 - 1}{X_3 + X_4 - 1}\right)$ is NOT finite.\\
\hline
(D) & $E\left[E\left(\frac{X_1 + X_2 + X_3 + X_4 - 2}{X_1 + X_2 - X_3 - X_4} \middle| X_1 + X_2 - X_3 - X_4\right)\right]$ is NOT finite.\\
\hline
\end{tabular}

\bigskip
\hfill (GATE ST 2021)
\\
\begin{tabular}{|p{1cm}|p{14cm}|}
\hline
\textbf{Q.43} &
Let $Y$ follow $N_8(0, I_8)$ distribution, where $I_8$ is the $8 \times 8$ identity matrix. Let $Y_1 = Y^\top \Sigma_1 Y$ and $Y_2 = Y^\top \Sigma_2 Y$ be independent and follow central chi-square distributions with 3 and 4 degrees of freedom, respectively, where $\Sigma_1$ and $\Sigma_2$ are $8 \times 8$ matrices. Then which of the following statements is/are true?

\begin{itemize}
    \item[(P)] $\Sigma_1$ and $\Sigma_2$ are idempotent.
    \item[(Q)] $\Sigma_1 \Sigma_2 = 0$, where $0$ is the $8 \times 8$ zero matrix.
\end{itemize} \\
\hline

(A) & P only\\
\hline
(B) & Q only\\
\hline
(C) & Both P and Q\\
\hline
(D) & Neither P nor Q \\
\hline
\end{tabular}

\bigskip
\hfill (GATE ST 2021)
\\

\textbf{Q.44 -- Q.55 Numerical Answer Type (NAT), carry TWO marks each (no negative marks).}

\bigskip
\begin{tabular}{|p{1cm}|p{14cm}|}
\hline
\textbf{Q.44} &
Let $(X, Y)$ have a bivariate normal distribution with joint probability density function
$$
f_{X,Y}(x,y) = \frac{1}{2\pi} e^{-(2x - 3x^2 - 2y^2)},
\quad -\infty < x,y < \infty.
$$
Then $8 E(XY)$ equals\\
\hline
\end{tabular}

\bigskip
\hfill (GATE ST 2021)
\\
\begin{tabular}{|p{1cm}|p{14cm}|}
\hline
\textbf{Q.45} &
Let $f: \mathbb{R} \times \mathbb{R} \to \mathbb{R}$ be defined by
$$
f(x,y) = 8x^2 - 2y,
$$
where $\mathbb{R}$ denotes the set of all real numbers. If $M$ and $m$ denote the maximum and minimum values of $f$, respectively, on the set
$$
\{(x,y) \in \mathbb{R} \times \mathbb{R} : x^2 + y^2 = 1 \},
$$
then $M - m$ equals (round off to 2 decimal places).\\
\hline
\end{tabular}

\bigskip
\hfill (GATE ST 2021)
\\
\begin{tabular}{|p{1cm}|p{14cm}|}
\hline
\textbf{Q.46} &
Let 
$$
A = [a \quad u_1 \quad u_2 \quad u_3], \quad B = [b \quad u_1 \quad u_2 \quad u_3], \quad C = [u_1 \quad u_2 \quad u_3 \quad a + b]
$$
be three $4 \times 4$ real matrices, where $a, b, u_1, u_2, u_3$ are $4 \times 1$ real column vectors. Let $\det(A)$, $\det(B)$ and $\det(C)$ denote the determinants of $A$, $B$ and $C$, respectively. If $\det(A) = 6$ and $\det(B) = 2$, then $\det(A + B) - \det(C)$ equals\\
\hline
\end{tabular}

\bigskip
\hfill (GATE ST 2021)
\\
\begin{tabular}{|p{1cm}|p{14cm}|}
\hline
\textbf{Q.47} &
Let $X$ be a random variable having moment generating function
$$
M(t) = \frac{e^{t} - 1}{t(1 - t)}, \quad t < 1.
$$
Then $P(X > 1)$ equals (round off to 2 decimal places).\\
\hline
\end{tabular}

\bigskip
\hfill (GATE ST 2021)
\\
\begin{tabular}{|p{1cm}|p{14cm}|}
\hline
\textbf{Q.48} &
Let $\{X_n\}_{n \geq 1}$ be a sequence of independent and identically distributed random variables each having uniform distribution on $[0,3]$. Let $Y$ be a random variable, independent of $\{X_n\}_{n \geq 1}$, having probability mass function
$$
P(Y = k) = \frac{e^{-1}}{k!}, \quad k = 0, 1, 2, \ldots,
$$
and zero otherwise.

Then $P(\max\{X_1, X_2, \ldots, X_Y\} \leq 1)$ equals (round off to 2 decimal places).\\
\hline
\end{tabular}

\bigskip
\hfill (GATE ST 2021)
\\
\begin{tabular}{|p{1cm}|p{14cm}|}
\hline
\textbf{Q.49} &
Let $\{X_n\}_{n \geq 1}$ be a sequence of independent and identically distributed random variables each having probability density function
$$
f(x) = e^{-x}, \quad x > 0,
$$
and zero otherwise. Let $X_{(n)} = \max\{X_1, X_2, \ldots, X_n\}$ for $n \geq 1$. If $Z$ is the random variable to which $\{X_{(n)} - \log_e n\}_{n \geq 1}$ converges in distribution as $n \to \infty$, then the median of $Z$ equals (round off to 2 decimal places).\\
\hline
\end{tabular}

\bigskip
\hfill (GATE ST 2021)
\\
\begin{tabular}{|p{1cm}|p{14cm}|}
\hline
\textbf{Q.50} &
Consider an amusement park where visitors arrive according to a Poisson process with rate 1. Upon arrival, a visitor spends a random amount of time in the park and then departs. The time spent by visitors are independent of one another, and independent of the arrival process, each having common probability density function
$$
f(x) = e^{-x}, \quad x > 0,
$$
and zero otherwise. If, at a given time point, there are 10 visitors in the park and $p$ is the probability that there will be exactly two more arrivals before the next departure, then $p$ equals\\
\hline
\end{tabular}

\bigskip
\hfill (GATE ST 2021)
\\
\begin{tabular}{|p{1cm}|p{14cm}|}
\hline
\textbf{Q.51} &
Let $\{0.90, 0.50, 0.01, 0.95\}$ be a realization of a random sample of size 4 from the probability density function
$$
f(x) = \frac{1 - \theta x}{1 - \theta/2}, \quad 0 < x < 1,
$$
and zero otherwise, where $0.5 \leq \theta < 1$. Then the maximum likelihood estimate of $\theta$ based on the observed sample equals (round off to 2 decimal places).\\
\hline
\end{tabular}

\bigskip
\hfill (GATE ST 2021)
\\
\begin{tabular}{|p{1cm}|p{14cm}|}
\hline
\textbf{Q.52} &
Let a random sample of size 100 from a normal population with unknown mean $\mu$ and variance 9 give the sample mean 5.608. Let $\Phi(\cdot)$ denote the distribution function of the standard normal random variable. If $\Phi(1.96) = 0.975$, $\Phi(1.64) = 0.95$, and the uniformly most powerful unbiased test based on the sample mean is used to test $H_0: \mu = 5.02$ against $H_1: \mu \neq 5.02$, then the p-value equals (round off to 3 decimal places).\\
\hline
\end{tabular}

\bigskip
\begin{tabular}{|p{1cm}|p{14cm}|}
\hline
\textbf{Q.53} &
Let $X$ be a discrete random variable with probability mass function

\begin{tabular}{|p{1cm}|p{1cm}|p{1cm}|p{1cm}|p{1cm}|}
\hline
x & 7 & 8 & 9 & 10 \\
\hline
$p_1(x)$ & 0.69 & 0.1 & 0.16 & 0.05 \\
\hline
$p_0(x)$ & 0.90 & 0.05 & 0.04 & 0.01\\
\hline
\end{tabular} 
\bigskip
To test $H_0: p = p_0$ against $H_1: p = p_1$, the power of the most powerful test of size 0.05 based on $X$ equals (round off to 2 decimal places).\\
\hline
\end{tabular}

\bigskip
\hfill (GATE ST 2021)
\\
\begin{tabular}{|p{1cm}|p{14cm}|}
\hline
\textbf{Q.54} &
Let $X_1, X_2, \ldots, X_{10}$ be a random sample from a probability density function $f_0(x) = f(x - \theta)$, $-\infty < x < \infty$, where $-\infty < \theta < \infty$ and $f(-x) = f(x)$ for $-\infty < x < \infty$. For testing $H_0: \theta = 1.2$ against $H_1: \theta \neq 1.2$, let $T_+$ denote the Wilcoxon signed-rank test statistic. If $n$ denotes the probability of the event $\{T_+ < 50\}$ under $H_0$, then $32 \times n$ equals (round off to 2 decimal places).\\
\hline
\end{tabular}

\bigskip
\hfill (GATE ST 2021)
\\
\begin{tabular}{|p{1cm}|p{14cm}|}
\hline
\textbf{Q.55} &
Consider the multiple linear regression model
$$
Y_i = \beta_0 + \beta_1 x_{1,i} + \beta_2 x_{2,i} + \cdots + \beta_{22} x_{22,i} + \varepsilon_i, \quad i=1, 2, \ldots, 123,
$$
where, for $j=0, 1, \ldots, 22$, the $\beta_j$'s are unknown parameters and the $\varepsilon_i$'s are independent and identically distributed $N(0, \sigma^2)$ random variables with $\sigma > 0$. If the sum of squares due to regression is 338.92, the total sum of squares is 522.30 and $R^2_{\text{adj}}$ denotes the value of adjusted $R^2$, then $100 R^2_{\text{adj}}$ equals (round off to 2 decimal places).\\
\hline
\end{tabular}

\bigskip
\hfill (GATE ST 2021)
\\

\end{document}
